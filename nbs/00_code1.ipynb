{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2119719\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 21990\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 20\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  \n",
    "\n",
    "subset_dataset = dataset['train'][:sample]['text']\n",
    "\n",
    "# Tokenize the text data in the new subset dataset with padding and truncation\n",
    "tokenized_dataset = tokenizer(\n",
    "    subset_dataset,\n",
    "    return_tensors='pt',\n",
    "    padding=True,  # Enable padding\n",
    "    truncation=True  # Enable truncation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
      "\n",
      "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
      "\n",
      "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n",
      "Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\n",
      "\n",
      "One day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were falling. Beep liked how the leaves fall and wanted to play with them. Beep drove under the tree and watched the leaves fall on him. He laughed and beeped his horn.\n",
      "\n",
      "Beep played with the falling leaves all day. When it was time to go home, Beep knew he needed more fuel. He went to the fuel place and got more healthy fuel. Now, Beep was ready to go fast and play again the next day. And Beep lived happily ever after.\n",
      "One day, a little fish named Fin was swimming near the shore. He saw a big crab and wanted to be friends. \"Hi, I am Fin. Do you want to play?\" asked the little fish. The crab looked at Fin and said, \"No, I don't want to play. I am cold and I don't feel fine.\"\n",
      "\n",
      "Fin felt sad but wanted to help the crab feel better. He swam away and thought of a plan. He remembered that the sun could make things warm. So, Fin swam to the top of the water and called to the sun, \"Please, sun, help my new friend feel fine and not freeze!\"\n",
      "\n",
      "The sun heard Fin's call and shone its warm light on the shore. The crab started to feel better and not so cold. He saw Fin and said, \"Thank you, little fish, for making me feel fine. I don't feel like I will freeze now. Let's play together!\" And so, Fin and the crab played and became good friends.\n"
     ]
    }
   ],
   "source": [
    "for example in tokenized_dataset['input_ids'][:3]:\n",
    "    # Decode the list of token IDs\n",
    "    decoded_text = tokenizer.decode(example, skip_special_tokens=True)\n",
    "    print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 219])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tokenized_dataset['input_ids']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 218]), torch.Size([20, 218]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data[:, :-1].contiguous()\n",
    "y = data[:, 1:].contiguous()\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([7454]) --> Labels: 2402\n",
      "Input: tensor([7454, 2402]) --> Labels: 257\n",
      "Input: tensor([7454, 2402,  257]) --> Labels: 640\n",
      "Input: tensor([7454, 2402,  257,  640]) --> Labels: 11\n",
      "Input: tensor([7454, 2402,  257,  640,   11]) --> Labels: 612\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Input: {x[0, :i+1]} --> Labels: {y[0,i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257 218\n"
     ]
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "sequence_len = x.size(1)\n",
    "\n",
    "print(vocab_size, sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 218, 36])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token Embedding\n",
    "n_embd = 36\n",
    "wte = nn.Embedding(vocab_size, n_embd) # word to embedding\n",
    "\n",
    "token_embd = wte(x)\n",
    "token_embd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([218, 36])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Position Embedding\n",
    "position = nn.Embedding(sequence_len, n_embd)\n",
    "\n",
    "position_embd = position(torch.arange(sequence_len))\n",
    "position_embd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 218, 36])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embd = token_embd + position_embd\n",
    "x_embd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_hidden_states = nn.LayerNorm(n_embd)\n",
    "x_embd_ln = ln_hidden_states(x_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = nn.Linear(n_embd, 4 * n_embd)\n",
    "fc2 = nn.Linear(4 * n_embd, n_embd)\n",
    "\n",
    "act = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 218, 36])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed forward output\n",
    "ffwd_out = fc1(x_embd_ln)\n",
    "ffwd_out = act(ffwd_out)\n",
    "ffwd_out = fc2(ffwd_out)\n",
    "\n",
    "ffwd_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 36)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_head = 4\n",
    "\n",
    "head_size = n_embd // n_head\n",
    "opt_size = n_head * head_size # output size\n",
    "head_size, opt_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 218, 108])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wqkv = nn.Linear(n_embd, 3 * opt_size)\n",
    "qkv = Wqkv(x_embd_ln)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 218, 3, 4, 9])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "qkv = rearrange(qkv, \"... (three h d) -> ... three h d\", three=3, h = n_head)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 218, 4, 9]),\n",
       " torch.Size([16, 218, 4, 9]),\n",
       " torch.Size([16, 218, 4, 9]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.unbind(dim=2)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 218, 218])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "softmax_scale = 1.0 / math.sqrt(q.shape[-1])\n",
    "\n",
    "scores = torch.einsum(\"bthd,bshd->bhts\", q, k * softmax_scale)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequence_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pc\\microsoft_phil1-5\\code.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pc/microsoft_phil1-5/code.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtriu(torch\u001b[39m.\u001b[39mfull((sequence_len, sequence_len), \u001b[39m-\u001b[39m\u001b[39m10000.0\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pc/microsoft_phil1-5/code.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m scores \u001b[39m=\u001b[39m scores \u001b[39m+\u001b[39m mask\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pc/microsoft_phil1-5/code.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scores\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sequence_len' is not defined"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.full((sequence_len, sequence_len), -10000.0), 1)\n",
    "scores = scores + mask\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 218, 36])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = torch.softmax(scores, dim=-1)\n",
    "\n",
    "attn_out = torch.einsum(\"bhts,bshd->bthd\", attention, v)\n",
    "\n",
    "attn_out = rearrange(attn_out, \"... h d -> ... (h d)\")\n",
    "attn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 218, 36])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_proj = nn.Linear(opt_size, n_embd)\n",
    "attn_out = out_proj(attn_out)\n",
    "attn_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 218, 36])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual = x_embd\n",
    "\n",
    "output = ffwd_out + attn_out + residual\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 218, 50257])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(n_embd, vocab_size)\n",
    "ln_output = nn.LayerNorm(n_embd)\n",
    "\n",
    "output = ln_output(output)\n",
    "\n",
    "logits = linear(output)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.2422, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "logits  = logits.view(-1, logits.shape[-1])\n",
    "labels = y.view(-1)\n",
    "\n",
    "loss = loss_fct(logits, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
